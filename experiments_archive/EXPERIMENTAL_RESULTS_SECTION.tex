% Experimental Results Section for Paper
% Network Structures as an Attack Surface: Topology-Based Privacy Leakage in Federated Learning

\section{Experimental Results}
\label{sec:results}

We present comprehensive experimental results evaluating topology-based privacy attacks across the full spectrum of adversarial knowledge capabilities. Through analysis of 2,620 total attack instances (520 complete knowledge baseline + 2,100 partial knowledge scenarios) spanning realistic adversarial constraints, our evaluation reveals systematic vulnerabilities that persist across practical deployment conditions.

\subsection{Phase 1: Baseline Attack Effectiveness Under Complete Knowledge}

Our initial evaluation establishes fundamental attack capabilities under complete topology knowledge across 520 experimental configurations. Table~\ref{tab:baseline_effectiveness} presents aggregate results demonstrating the theoretical upper bounds of topology-based privacy leakage.

\begin{table}[!t]
\caption{Baseline Attack Effectiveness Under Complete Topology Knowledge}
\label{tab:baseline_effectiveness}
\centering
\footnotesize
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Attack Vector} & \textbf{Success Rate} & \textbf{95\% CI} & \textbf{Sample Size} \\
\midrule
Communication Pattern & 84.1\% & [83.4\%, 84.8\%] & n=520 \\
Parameter Magnitude & 65.0\% & [64.6\%, 65.3\%] & n=520 \\
Topology Structure & 47.2\% & [45.2\%, 49.1\%] & n=520 \\
\bottomrule
\end{tabular}
\end{table}

The communication pattern attack demonstrates the highest effectiveness, exploiting observable message exchange frequencies to cluster nodes based on data similarity. This attack succeeds by identifying nodes with similar data distributions that require fewer communication rounds to reach consensus in decentralized settings. Parameter magnitude attacks achieve moderate effectiveness by profiling statistical properties of update magnitudes, while topology structure attacks show the highest variability, succeeding primarily when organizational constraints create systematic position-distribution correlations.

Cross-dataset analysis with integrated subsampling effects reveals comprehensive vulnerability patterns across deployment scenarios. Figure~\ref{fig:dataset_violin} demonstrates equivalent attack effectiveness between MNIST digit classification and HAM10000 medical imaging across all three attack vectors. Each violin combines Phase 1 baseline data with Phase 3 subsampling results, showing the complete distribution of attack success rates from no subsampling through very strong subsampling constraints (20\% clients, 50\% data). The distributions illustrate both domain-agnostic vulnerability and the range of effectiveness under realistic deployment constraints, with scattered data points revealing the graduated degradation from baseline to maximum subsampling protection.

\begin{figure}[!t]
\centering
\includegraphics[width=0.48\textwidth]{figures/phase1_figures/dataset_violin_plot.pdf}
\caption{Integrated vulnerability analysis combining Phase 1 baseline and Phase 3 subsampling results. Each violin shows the complete distribution of attack success rates for MNIST and HAM10000 datasets, incorporating baseline effectiveness and all subsampling scenarios. Scattered points within each violin represent individual experimental configurations, demonstrating the range from no subsampling (upper values) to very strong subsampling (lower values). The distributions confirm domain-agnostic vulnerability and persistent effectiveness above security thresholds.}
\label{fig:dataset_violin}
\end{figure}

\subsection{Privacy Protection Mechanism Evaluation}

Our evaluation incorporates state-of-the-art differential privacy protection with per-round privacy parameters $\varepsilon \in \{1.0, 4.0, 8.0\}$ representing strong, medium, and weak privacy protection respectively. Table~\ref{tab:dp_effectiveness} summarizes attack degradation under varying privacy protection levels.

\begin{table}[!t]
\caption{Attack Effectiveness Under Differential Privacy Protection}
\label{tab:dp_effectiveness}
\centering
\footnotesize
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Privacy Level} & \textbf{$\varepsilon$} & \textbf{Comm Pattern} & \textbf{Param Magnitude} & \textbf{Topology Structure} \\
\midrule
No DP & $\infty$ & 84.1\% & 65.0\% & 47.2\% \\
Weak DP & 8.0 & 81.3\% & 62.1\% & 45.8\% \\
Medium DP & 4.0 & 78.9\% & 58.7\% & 43.4\% \\
Strong DP & 1.0 & 74.2\% & 52.8\% & 39.1\% \\
\midrule
\textbf{Max Reduction} & - & \textbf{11.8\%} & \textbf{18.8\%} & \textbf{17.2\%} \\
\bottomrule
\end{tabular}
\end{table}

Differential privacy provides measurable but insufficient protection against topology-based attacks. Even under strong privacy protection ($\varepsilon = 1.0$), communication pattern attacks maintain 74.2\% effectiveness, while parameter magnitude attacks achieve 52.8\% success rates. The limited degradation occurs because these attacks exploit structural relationships and aggregate behavioral patterns that remain robust to parameter-level noise injection.

\subsection{Phase 2: Attack Robustness Under Realistic Adversarial Knowledge}

We systematically evaluate attack effectiveness across five realistic partial knowledge scenarios representing practical adversarial capabilities. Table~\ref{tab:realistic_scenarios} presents comprehensive results across 2,100 attack evaluations.

\begin{table*}[!t]
\caption{Attack Effectiveness Under Realistic Partial Topology Knowledge Scenarios}
\label{tab:realistic_scenarios}
\centering
\footnotesize
\setlength{\tabcolsep}{6pt}
\begin{tabular}{@{}lcccccc@{}}
\toprule
\textbf{Knowledge Scenario} & \textbf{Communication Pattern} & \textbf{Parameter Magnitude} & \textbf{Topology Structure} & \textbf{Effective Attacks} & \textbf{Scenario Status} \\
\midrule
Complete Knowledge (Baseline) & 84.1\% & 65.0\% & 47.2\% & 3/3 (100\%) & Fully Effective \\
\midrule
\textbf{Local Adversary Scenarios} & & & & & \\
Neighborhood 1-hop & 68.8\% & 47.2\% & 47.8\% & 3/3 (100\%) & Fully Effective \\
Neighborhood 2-hop & 76.5\% & 62.3\% & 47.9\% & 3/3 (100\%) & Fully Effective \\
\midrule
\textbf{External Adversary Scenarios} & & & & & \\
Statistical Knowledge & 86.0\% & 65.4\% & 27.6\% & 2/3 (67\%) & Partially Effective \\
\midrule
\textbf{Insider Threat Scenarios} & & & & & \\
Organizational 3-groups & 31.7\% & 42.5\% & 74.1\% & 3/3 (100\%) & Fully Effective \\
Organizational 5-groups & 53.3\% & 61.4\% & 53.6\% & 3/3 (100\%) & Fully Effective \\
\midrule
\textbf{Overall Robustness} & & & & \textbf{4/5 (80\%)} & \textbf{High Robustness} \\
\bottomrule
\end{tabular}
\end{table*}

The evaluation reveals remarkable attack robustness across realistic adversarial constraints. Four of five scenarios (80\%) maintain full attack effectiveness, with all three attack vectors remaining above the 30\% success threshold. Most significantly, certain partial knowledge scenarios achieve superior performance to complete knowledge baselines, indicating that focused information can be more valuable than comprehensive data.

\subsubsection{Local Adversary Analysis}

Local adversaries with neighborhood visibility demonstrate consistent attack effectiveness. One-hop knowledge scenarios achieve 68.8\%, 47.2\%, and 47.8\% success rates for communication pattern, parameter magnitude, and topology structure attacks respectively. Expanding to two-hop knowledge improves performance to 76.5\%, 62.3\%, and 47.9\%, approaching complete knowledge effectiveness for communication and parameter attacks.

The consistent effectiveness under neighborhood constraints reflects the local nature of topology-based vulnerabilities. Communication patterns remain observable within limited network neighborhoods, while parameter magnitude signatures persist regardless of global topology knowledge. Topology structure attacks show minimal degradation and even slight improvement, suggesting that local structural information provides sufficient inference capability.

\subsubsection{External Adversary Analysis}

External adversaries with statistical topology knowledge demonstrate mixed results compared to complete knowledge baselines. Communication pattern attacks show marginal improvement to 86.0\% (2.3\% increase), while parameter magnitude attacks achieve slight improvement to 65.4\% (0.8\% increase). Topology structure attacks experience significant degradation to 27.6\% (41.5\% reduction), falling below the effectiveness threshold.

The modest improvements in communication and parameter attacks indicate that statistical topology knowledge provides sufficient information for these attack vectors, while the substantial degradation in topology structure attacks suggests this approach requires more detailed structural information. These results demonstrate that high-level architectural knowledge enables selective attack effectiveness rather than universal improvements.

\subsubsection{Insider Threat Analysis}

Organizational knowledge scenarios produce the most dramatic and unexpected results. Coarse organizational grouping (3-groups) enables topology structure attacks to achieve 74.1\% effectivenessâ€”a remarkable 57.0\% improvement over the complete knowledge baseline. Fine-grained organizational structure (5-groups) maintains this advantage with 53.6\% effectiveness, representing a 13.7\% improvement. Conversely, communication pattern and parameter magnitude attacks experience substantial degradation under organizational constraints, with reductions ranging from 5.4\% to 62.3\%.

These findings reveal that institutional relationship information provides powerful attack vectors specifically for topology structure inference while significantly constraining communication and parameter-based approaches. The pattern suggests that organizational structure creates more predictable data distribution patterns than purely topological relationships, enabling superior topology inference through institutional specialization signatures while masking communication and parameter patterns.

\subsection{Phase 3: Deployment Scenarios with Subsampling Effects}

We evaluate attack robustness under realistic deployment constraints incorporating client and data subsampling across 288 configurations. Figure~\ref{fig:subsampling_flow} presents results across moderate, strong, and very strong subsampling scenarios, with percentage reductions from baseline annotated for each data point.

\begin{figure}[!t]
\centering
\includegraphics[width=0.48\textwidth]{figures/phase3_figures/subsampling_flow.pdf}
\caption{Attack effectiveness degradation under client and data subsampling constraints. Lines show success rates for three attack vectors across increasing subsampling strength, with percentage decreases from baseline annotated at each point. Even under very strong subsampling (20\% clients, 50\% data), attacks maintain effectiveness above security thresholds.}
\label{fig:subsampling_flow}
\end{figure}

Subsampling provides meaningful but insufficient privacy amplification against topology-based attacks. Even under very strong subsampling (20\% client participation, 50\% data sampling), communication pattern attacks maintain 62.3\% effectiveness while parameter magnitude attacks achieve 52.8\% success rates. The degradation pattern is non-monotonic, suggesting that aggressive subsampling paradoxically concentrates attacks on the most informative participants.

The persistence of attack effectiveness under subsampling reflects the structural determinism inherent in topology-constrained communication. Unlike gradient-based attacks that benefit from participant uncertainty, topology-based attacks exploit mandatory communication relationships that remain observable regardless of sampling rates.

\subsection{Phase 4: Enterprise-Scale Analysis}

Our synthetic simulation framework enables evaluation of networks with 50-500 nodes while maintaining computational tractability. Figure~\ref{fig:network_scaling_topology} presents attack effectiveness trends across enterprise scales, comparing real experimental data (5-30 nodes) with synthetic simulations (50-500 nodes) for each network topology. Figure~\ref{fig:network_scaling_dp} demonstrates scale independence under differential privacy protection.

\begin{figure}[!t]
\centering
\includegraphics[width=0.48\textwidth]{figures/phase4_figures/network_scaling_topology.pdf}
\caption{Attack effectiveness scaling by network topology. Solid lines represent real experimental data (5-30 nodes) while dashed lines show synthetic simulations (50-500 nodes). All topologies demonstrate scale independence with consistent effectiveness across network sizes.}
\label{fig:network_scaling_topology}
\end{figure}

\begin{figure}[!t]
\centering
\includegraphics[width=0.48\textwidth]{figures/phase4_figures/network_scaling_dp.pdf}
\caption{Attack effectiveness scaling under differential privacy protection. Comparison of networks with and without DP protection across network scales, showing consistent effectiveness gaps regardless of network size. Real data (solid lines) for 5-30 nodes and synthetic data (dashed lines) for 50-500 nodes.}
\label{fig:network_scaling_dp}
\end{figure>

The analysis reveals scale independence of attack effectiveness across all evaluated network sizes. Communication pattern attacks maintain 68.7\% average effectiveness, parameter magnitude attacks achieve 55.9\% success rates, and topology structure attacks demonstrate 48.3\% effectiveness across the 50-500 node range. Signal strength metrics remain robust (0.68-0.99) across all tested scales, confirming that fundamental information channels persist regardless of deployment size.

The consistency between real-world experiments (5-30 nodes) and large-scale simulations validates our synthetic modeling approach while demonstrating that organizational scale provides no inherent privacy protection. Attack effectiveness remains stable or slightly improves with network size, challenging assumptions that privacy protection improves through dilution effects in large-scale federated learning deployments.

The network topology scaling analysis reveals consistent attack effectiveness across both real experimental data and synthetic simulations. Star topologies maintain high vulnerability with slight performance variations, while ring and line topologies demonstrate remarkably stable effectiveness. Complete topologies show lower overall performance but maintain consistency across scales. The seamless transition between real and synthetic data validates our modeling approach and confirms that network size provides no inherent privacy protection.

Differential privacy protection maintains consistent effectiveness gaps across all network scales. The parallel scaling trends for protected and unprotected scenarios demonstrate that DP provides consistent but insufficient protection regardless of network size. This finding challenges assumptions that privacy protection benefits from scale effects in large federated learning deployments.

\subsection{Statistical Significance and Effect Size Analysis}

All reported results include comprehensive statistical validation with 95\% confidence intervals and effect size analysis using Cohen's d for practical significance assessment. Table~\ref{tab:effect_sizes} presents effect size magnitudes for key comparisons.

\begin{table}[!t]
\caption{Effect Size Analysis for Key Experimental Comparisons}
\label{tab:effect_sizes}
\centering
\footnotesize
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Comparison} & \textbf{Cohen's d} & \textbf{Magnitude} \\
\midrule
Complete vs. 1-hop Knowledge & 0.84 & Large \\
Complete vs. 2-hop Knowledge & 0.43 & Medium \\
Complete vs. Statistical Knowledge & 0.12 & Small \\
Complete vs. Organizational (3-groups) & 1.23 & Large \\
Complete vs. Organizational (5-groups) & 0.67 & Medium \\
\midrule
No DP vs. Strong DP & 0.58 & Medium \\
Small vs. Large Networks & 0.09 & Negligible \\
\bottomrule
\end{tabular}
\end{table}

Large effect sizes for organizational knowledge scenarios confirm the practical significance of institutional information advantages, while negligible network size effects validate scale independence findings. Medium effect sizes for differential privacy protection indicate meaningful but insufficient defense capabilities.

\subsection{Performance Changes Under Partial Knowledge Constraints}

Our analysis reveals mixed performance changes under partial knowledge scenarios compared to Phase 1 baselines. While most scenarios show expected performance degradation, several demonstrate counter-intuitive improvements over Phase 1 baselines. Topology structure attacks benefit significantly from organizational structure awareness (57.0\% improvement for 3-groups, 13.7\% for 5-groups) while showing minimal changes under neighborhood constraints (1.3\% and 1.6\% improvements for 1-hop and 2-hop respectively). Statistical knowledge scenarios show modest improvements for communication pattern (2.3\%) and parameter magnitude (0.8\%) attacks, while significantly degrading topology structure attacks (41.5\% reduction). These mixed patterns suggest that focused partial information can enable more targeted attack strategies for specific attack vectors while constraining others, demonstrating the complex interplay between knowledge constraints and attack effectiveness.

\subsection{Summary of Key Findings}

Our comprehensive experimental evaluation across 2,620 attack instances demonstrates systematic topology-based privacy vulnerabilities that persist across realistic deployment conditions:

1. **High Baseline Effectiveness**: Communication pattern attacks achieve 84.1\% success under complete knowledge, with parameter magnitude (65.0\%) and topology structure (47.2\%) attacks providing complementary inference capabilities.

2. **Knowledge Constraint Robustness**: 80\% of realistic partial knowledge scenarios maintain full attack effectiveness, with certain scenarios outperforming complete knowledge baselines by up to 57.0\%.

3. **Limited Privacy Mechanism Protection**: Differential privacy provides maximum 18.8\% attack degradation, while subsampling amplification achieves 25.9\% maximum reduction under extreme constraints.

4. **Scale Independence**: Attack effectiveness remains stable from 5-node networks to simulated 500-node deployments, indicating no inherent privacy protection through organizational scale.

5. **Domain-Agnostic Vulnerability and Subsampling Robustness**: Medical imaging data shows equivalent vulnerability to digit classification (difference <1\%) across all subsampling scenarios, demonstrating universal applicability across data modalities and deployment constraints. Even under very strong subsampling (20\% clients, 50\% data), attack effectiveness remains above security thresholds for both datasets.

These findings establish network topology as a critical attack surface requiring fundamental reconceptualization of privacy guarantees in federated learning systems. The mathematical precision of our results, validated across 2,620 attack instances with comprehensive statistical analysis, demonstrates that topology-based vulnerabilities represent systematic rather than incidental privacy risks. The domain-agnostic nature of these vulnerabilities, scale independence across enterprise deployments, and persistence under state-of-the-art privacy mechanisms necessitate topology-aware defense mechanisms that address structural leakage channels beyond traditional content protection approaches.

The experimental evidence conclusively demonstrates that current federated learning privacy frameworks fail to account for the rich information embedded in network structure and communication patterns. Our results provide the empirical foundation necessary for developing principled approaches to topology-aware privacy protection in distributed learning systems.